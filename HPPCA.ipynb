{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as io\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from scipy.stats import entropy\n",
    "import time\n",
    "from random import random\n",
    "from random import randint\n",
    "import argparse\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset,TensorDataset, DataLoader\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Load feature data\n",
    "def load_data(path,file):\n",
    "    name=path+file\n",
    "    m=loadmat(name)\n",
    "    x=torch.tensor(m['feature']).to(device)\n",
    "    return x.float()\n",
    "\n",
    "def load_data_all(path,names):\n",
    "    emptyx=1\n",
    "    nc=len(names)\n",
    "    for j in range(nc):\n",
    "        x=load_data(path,names[j])\n",
    "        x=x.to(device)\n",
    "        if emptyx:\n",
    "            allx=x\n",
    "            emptyx=0\n",
    "        else:\n",
    "            allx=torch.cat((allx,x),dim=0)\n",
    "        l=j\n",
    "        if j==0:\n",
    "            y=torch.zeros(x.shape[0]).to(device)+l\n",
    "        else:\n",
    "            y=torch.cat((y,torch.zeros(x.shape[0]).to(device)+l))\n",
    "        if (j%200==199)|(j==nc-1):\n",
    "            print(j+1)   \n",
    "    return allx,y\n",
    "\n",
    "\n",
    "def tr(a,b):\n",
    "    dab=torch.diagonal(a@b, dim1=-1)\n",
    "    return torch.sum(dab,dim=1)\n",
    "\n",
    "def tr1(a,b):\n",
    "    return torch.sum(a.t()*b,dim=[1,2])\n",
    "\n",
    "def computeClassPPCAs(path,names,device,q=200):\n",
    "    nc = len(names)\n",
    "    la=0.01\n",
    "    for i in range(nc):\n",
    "        name = '%sfeatures_640/%s.mat'%(path, names[i])\n",
    "        m=loadmat(name)\n",
    "        x=torch.tensor(m['feature']).float().to(device)\n",
    "        if i==0:\n",
    "            print(x.shape)\n",
    "        mx=torch.mean(x,dim=0)\n",
    "        xx=(x-mx).t()@(x-mx)/x.shape[0]\n",
    "        u,s,v = torch.linalg.svd(xx)\n",
    "        s[s < la] = la\n",
    "        Sigmai=(u*s)@u.t()\n",
    "        name=path+'Model/'+names[i]+'.pth'\n",
    "        torch.save({'mx':mx,'L':u[:,0:q].t(),'S':s[0:q],'Sigma':Sigmai},name)    \n",
    "        if (i%200==199)|(i==nc-1):\n",
    "            print(i+1)   \n",
    "        #self.sxx[i] = para_dict['sxx']\n",
    "    print('done computing class models')\n",
    "    #print(mu.shape,L.shape,S.shape)\n",
    "\n",
    "def loadClassPPCAs(path,names,device,q, loadSigma=0):\n",
    "    nc = len(names)\n",
    "    la=0.01\n",
    "    for i in range(nc):\n",
    "        full_feature_dir = '%s/%s.pth'%(path, names[i])\n",
    "        para_dict = torch.load(full_feature_dir)\n",
    "        mx=para_dict['mx'].squeeze()\n",
    "        Li=para_dict['L']\n",
    "        Si=para_dict['S'].squeeze()\n",
    "        if i==0:\n",
    "            print(para_dict.keys())\n",
    "            print(Li.shape,Si.shape)\n",
    "            d=mx.shape[0]\n",
    "            mu=torch.zeros(nc,d,device=device)\n",
    "            L=torch.zeros(nc,q,Li.shape[1],device=device)\n",
    "            S=torch.zeros(nc,Si.shape[0],device=device)\n",
    "            if loadSigma:\n",
    "                Sigma=torch.zeros(nc,d,d,device=device)\n",
    "        mu[i,:]=mx.to(device)\n",
    "        L[i,:,:]=Li[:q,:].to(device)\n",
    "        if loadSigma:\n",
    "            if 'Sigma'in para_dict.keys():\n",
    "                Sigma[i,:,:] = para_dict['Sigma'].to(device)\n",
    "            else:\n",
    "                Si=Si**2\n",
    "                Sigma[i,:,:] = (Li.t()*Si)@Li+la*torch.eye(d,device=device)\n",
    "        S[i,:]=Si.to(device)\n",
    "        #self.sxx[i] = para_dict['sxx']\n",
    "    print('done loading classes')\n",
    "    #print(mu.shape,L.shape,S.shape)\n",
    "    if not loadSigma:\n",
    "        return mu,L,S\n",
    "    return mu,L,S,Sigma\n",
    "\n",
    "def response(x1, mu, L, S,la):\n",
    "    # response using L,S (fast), using the math computation above\n",
    "    # xSigma^-1 x = x^Tx/lambda - u^Tu/lambda where u = S/(S^2+lambda)^0.5Lx\n",
    "    x = x1 - mu\n",
    "    if S.shape[0]==0:\n",
    "        return torch.sum(x ** 2, dim=1)\n",
    "    Lx = x @ L.t()\n",
    "    Qx = ( torch.sqrt(S) / torch.sqrt(S  + la)).unsqueeze(0) * Lx\n",
    "    return (torch.sum(x ** 2, dim=1) - torch.sum(Qx ** 2, dim=1)) / la#+sum(torch.log(S+la))\n",
    "\n",
    "def classify(x,mx,L,S,q,la):\n",
    "    nj=x.shape[0]\n",
    "    nc=mx.shape[0]\n",
    "    out=torch.zeros(nj,nc,device=device)\n",
    "    for i in range(nc):\n",
    "        r=response(x,mx[i,:],L[i,:q,:],S[i,:q],la)\n",
    "        out[:,i] = r\n",
    "    py=torch.argmin(out,dim=1)\n",
    "    return py\n",
    "\n",
    "def B_distance(mx1,Sigma1,mx2,Sigma2):\n",
    "    mu=mx1-mx2\n",
    "    Sigma=torch.linalg.inv((Sigma2+Sigma1)/2)\n",
    "    #print(Sigma.shape,mu.shape)\n",
    "    Simu=Sigma@mu.unsqueeze(2)\n",
    "    #print(Simu.shape)\n",
    "    dis= mu.unsqueeze(1)@Simu\n",
    "    return dis.squeeze()/8\n",
    "\n",
    "def test_PPCA(test_loader,mu,L,S,q=20,la=0.01):\n",
    "    nc=mu.shape[0]\n",
    "    total = 0\n",
    "    wrong = 0\n",
    "    total_wrong = 0\n",
    "    start = time.time()\n",
    "    for data in test_loader:\n",
    "        features, labels = data\n",
    "        labels = torch.squeeze(labels)\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        label = classify(features, mu, L, S, q, la)\n",
    "\n",
    "        total_wrong += torch.sum(label != labels)\n",
    "        # wrong_list1.append(wrong/len(py))\n",
    "\n",
    "        total += len(labels)\n",
    "    end = time.time()\n",
    "        #print('Computation time is', end - start)\n",
    "    #print('super acc:',100*super_correct/total)\n",
    "    acc=1-total_wrong.item()/total\n",
    "    print('q:%d,accuracy:%.4f,t:%.1f' %(q,acc,end - start))  \n",
    "    return acc\n",
    "\n",
    "def generate_pnames(names,nruns=10,nn=100):\n",
    "    pnames={}\n",
    "    for it in range(nruns):    \n",
    "        names=np.random.permutation(names)\n",
    "        pnames[it+1]=names[:nn]\n",
    "    torch.save(pnames,'pnames.pth')\n",
    "\n",
    "def load_subsamples(path,names,nsamples):\n",
    "    emptyx=1\n",
    "    nc=len(names)\n",
    "    \n",
    "    for i in range(nc):\n",
    "        xi=load_data(path,names[i])\n",
    "        xi=xi.to(device)\n",
    "        if emptyx:\n",
    "            d=xi.shape[1]\n",
    "            x=torch.zeros((nc*nsamples,d),device=device)\n",
    "            print(x.shape)\n",
    "            y=torch.zeros(nc*nsamples,device=device)\n",
    "            emptyx=0\n",
    "        j=torch.randperm(xi.shape[1],device=device)\n",
    "        x[(i*nsamples):((i+1)*nsamples),:]=xi[j[:nsamples],:]\n",
    "        y[(i*nsamples):((i+1)*nsamples)]=torch.zeros(nsamples,device=device)+i\n",
    "        if (i%200==199)|(i==nc-1):\n",
    "            print(i+1)   \n",
    "    return x,y\n",
    "\n",
    "def subsample_data(path,names):\n",
    "    traind={}\n",
    "    for it in range(5):\n",
    "        x,y=load_subsamples(path+'features_640/',names,20)\n",
    "        traind[it+1]=(x,y)\n",
    "    torch.save(traind,'c:/training/imagenet/train_raw.pth')\n",
    "    \n",
    "def generateSuper(mu,sigma):\n",
    "    # the superclass mean and sigma\n",
    "    mu,sigma=mu.to(device),sigma.to(device)\n",
    "    superMu=torch.mean(mu,dim=0)\n",
    "    s_mu=mu-superMu\n",
    "    n=mu.shape[0]\n",
    "    d=mu.shape[1]\n",
    "    xx=s_mu.unsqueeze(2)@s_mu.unsqueeze(1)\n",
    "    superSigma=torch.mean(xx,dim=0)+torch.mean(sigma,dim=0)\n",
    "    return superMu,superSigma\n",
    "\n",
    "def updateParameters(ind, smu, sSigma, mu_p, Sigma_p):\n",
    "    nsc=smu.shape[0]\n",
    "    for i in range(nsc):\n",
    "        mui,si=generateSuper(mu_p[ind == i,:],Sigma_p[ind == i,:,:])\n",
    "        smu[i,:] = mui\n",
    "        sSigma[i,:,:]=si\n",
    "    return smu, sSigma\n",
    "\n",
    "def updateLS(Sigma,q=20, la=0.01):\n",
    "    u, s, v = torch.linalg.svd(Sigma, full_matrices=True)\n",
    "    L=v[:,:q, :]\n",
    "    S = s[:,:q]\n",
    "    return L,S\n",
    "\n",
    "def getIndex(ind,nsc,nc):\n",
    "    indexDict={}\n",
    "    for i in range(nsc):\n",
    "        indexDict[i] = []\n",
    "    for i in range(nc):\n",
    "        indexDict[int(ind[i])].append(i)\n",
    "    return indexDict\n",
    "\n",
    "\n",
    "#path='d:/datasets/Imagenet/'\n",
    "path = 'd:/datasets/ILSVRC2016/'\n",
    "name = path+'train.txt'\n",
    "with open(name, 'r') as f:\n",
    "    names = f.read().splitlines()\n",
    "#names=pnames[it+1]\n",
    "nc=len(names)\n",
    "print(nc)\n",
    "#computeClassPPCAs(path,names,device)\n",
    "#mu,L,S,Sigma=loadClassPPCAs(path+'model_640',names,device)\n",
    "#xt,yt=load_data_all(path+'features_val_640/',names)\n",
    "#print(xt.shape,yt.shape)\n",
    "#data=TensorDataset(xt,yt.long())\n",
    "#test_loader=DataLoader(data,batch_size=10000,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "1000\n",
      "done loading classes\n"
     ]
    }
   ],
   "source": [
    "# load image class mdoels\n",
    "\n",
    "def loadClassPPCAs(path,names,device,q,loadSigma=0):\n",
    "    nc = len(names)\n",
    "    la=0.01\n",
    "    for i in range(nc):\n",
    "        full_feature_dir = '%s/%s.pth'%(path, names[i])\n",
    "        para_dict = torch.load(full_feature_dir)\n",
    "        mx=para_dict['mx'].squeeze()\n",
    "        Li=para_dict['L']\n",
    "        Si=para_dict['S'].squeeze()\n",
    "        if i==0:\n",
    "            print(para_dict.keys())\n",
    "            print(Li.shape,Si.shape)\n",
    "            d=mx.shape[0]\n",
    "            mu=torch.zeros(nc,d,device=device)\n",
    "            L=torch.zeros(nc,Li.shape[0],Li.shape[1],device=device)\n",
    "            S=torch.zeros(nc,Si.shape[0],device=device)\n",
    "            if loadSigma:\n",
    "                Sigma=torch.zeros(nc,d,d,device=device)\n",
    "        mu[i,:]=mx\n",
    "        L[i,:,:]=Li\n",
    "        if loadSigma:\n",
    "            if 'Sigma'in para_dict.keys():\n",
    "                Sigma[i,:,:] = para_dict['Sigma']\n",
    "            else:\n",
    "                Si=Si**2\n",
    "                Sigma[i,:,:] = (Li.t()*Si)@Li+la*torch.eye(d,device=device)\n",
    "        S[i,:]=Si\n",
    "        #self.sxx[i] = para_dict['sxx']\n",
    "        if (i%1000==999)|(i==nc-1):\n",
    "            print(i+1)   \n",
    "    print('done loading classes')\n",
    "    #print(mu.shape,L.shape,S.shape)\n",
    "    if not loadSigma:\n",
    "        return mu,L,S\n",
    "    return mu,L,S,Sigma\n",
    "\n",
    "mu,L,S=loadClassPPCAs(path+'model_640',names,device,q=50)\n",
    "#mu,L,S=loadClassPPCAs('e:/datasets/imagenet/model_640',names,device,q=50)\n",
    "#mu,L,S,Sigma=loadClassPPCAs(path+'model_640',names,device,q=50,loadSigma=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'mu':mu,'L':L,'S':S},'c:/training/Imagenet/model_1k_q50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torch.load('c:/training/Imagenet/model_10k_q50.pth')\n",
    "mu=m['mu']\n",
    "L=m['L']\n",
    "S=m['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "m=torch.load(path+'features_val_640.pth')\n",
    "xt=m['xt']\n",
    "yt=m['yt']\n",
    "data=TensorDataset(xt,yt.long())\n",
    "test_loader=DataLoader(data,batch_size=50000,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'xt':xt,'yt':yt},'d:/datasets/Imagenet/test_1k.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "xt,yt=load_data_all(path+'features_val_640/',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:1,q:50,r:50,nsc:33,density:0.081,speedup:12.4,accuracy:0.673,super_acc:0.831\n",
      "T:5,q:50,r:50,nsc:33,density:0.214,speedup:4.7,accuracy:0.734,super_acc:0.979\n",
      "   T   q   r  i  nsc   density    speedup      acc  super_acc\n",
      "0  1  50  50  1   33  0.080550  12.414723  0.67272    0.83092\n",
      "1  5  50  50  1   33  0.213927   4.674489  0.73390    0.97928\n",
      "T:1,q:50,r:50,nsc:33,density:0.073,speedup:13.8,accuracy:0.668,super_acc:0.819\n",
      "T:5,q:50,r:50,nsc:33,density:0.215,speedup:4.6,accuracy:0.733,super_acc:0.981\n",
      "   T   q   r  i  nsc   density    speedup      acc  super_acc\n",
      "0  1  50  50  1   33  0.080550  12.414723  0.67272    0.83092\n",
      "1  5  50  50  1   33  0.213927   4.674489  0.73390    0.97928\n",
      "2  1  50  50  2   33  0.072659  13.762939  0.66784    0.81862\n",
      "3  5  50  50  2   33  0.215158   4.647740  0.73346    0.98138\n",
      "T:1,q:50,r:50,nsc:33,density:0.072,speedup:13.8,accuracy:0.673,super_acc:0.822\n",
      "T:5,q:50,r:50,nsc:33,density:0.212,speedup:4.7,accuracy:0.734,super_acc:0.979\n",
      "   T   q   r  i  nsc   density    speedup      acc  super_acc\n",
      "0  1  50  50  1   33  0.080550  12.414723  0.67272    0.83092\n",
      "1  5  50  50  1   33  0.213927   4.674489  0.73390    0.97928\n",
      "2  1  50  50  2   33  0.072659  13.762939  0.66784    0.81862\n",
      "3  5  50  50  2   33  0.215158   4.647740  0.73346    0.98138\n",
      "4  1  50  50  3   33  0.072432  13.805999  0.67318    0.82212\n",
      "5  5  50  50  3   33  0.212007   4.716816  0.73404    0.97916\n",
      "T:1,q:50,r:50,nsc:33,density:0.076,speedup:13.2,accuracy:0.666,super_acc:0.817\n",
      "T:5,q:50,r:50,nsc:33,density:0.222,speedup:4.5,accuracy:0.734,super_acc:0.981\n",
      "   T   q   r  i  nsc   density    speedup      acc  super_acc\n",
      "0  1  50  50  1   33  0.080550  12.414723  0.67272    0.83092\n",
      "1  5  50  50  1   33  0.213927   4.674489  0.73390    0.97928\n",
      "2  1  50  50  2   33  0.072659  13.762939  0.66784    0.81862\n",
      "3  5  50  50  2   33  0.215158   4.647740  0.73346    0.98138\n",
      "4  1  50  50  3   33  0.072432  13.805999  0.67318    0.82212\n",
      "5  5  50  50  3   33  0.212007   4.716816  0.73404    0.97916\n",
      "6  1  50  50  4   33  0.075554  13.235483  0.66590    0.81706\n",
      "7  5  50  50  4   33  0.222370   4.497014  0.73438    0.98118\n",
      "T:1,q:50,r:50,nsc:33,density:0.071,speedup:14.2,accuracy:0.675,super_acc:0.818\n",
      "T:5,q:50,r:50,nsc:33,density:0.204,speedup:4.9,accuracy:0.733,super_acc:0.975\n",
      "   T   q   r  i  nsc   density    speedup      acc  super_acc\n",
      "0  1  50  50  1   33  0.080550  12.414723  0.67272    0.83092\n",
      "1  5  50  50  1   33  0.213927   4.674489  0.73390    0.97928\n",
      "2  1  50  50  2   33  0.072659  13.762939  0.66784    0.81862\n",
      "3  5  50  50  2   33  0.215158   4.647740  0.73346    0.98138\n",
      "4  1  50  50  3   33  0.072432  13.805999  0.67318    0.82212\n",
      "5  5  50  50  3   33  0.212007   4.716816  0.73404    0.97916\n",
      "6  1  50  50  4   33  0.075554  13.235483  0.66590    0.81706\n",
      "7  5  50  50  4   33  0.222370   4.497014  0.73438    0.98118\n",
      "8  1  50  50  5   33  0.070617  14.160908  0.67488    0.81816\n",
      "9  5  50  50  5   33  0.203688   4.909475  0.73336    0.97508\n"
     ]
    }
   ],
   "source": [
    "# Evaluate HPPCA and HPPCA raw\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def classifyT(x, mx, L, S,q,la,T):\n",
    "    nj = x.shape[0]\n",
    "\n",
    "    nc = mx.shape[0]\n",
    "    out = torch.zeros(nj, nc, device=device)\n",
    "    for i in range(nc):\n",
    "        r = response(x, mx[i, :], L[i, :q, :], S[i, :q],la)\n",
    "        out[:, i] = r\n",
    "        sorte, indices = torch.sort(out,dim=1)\n",
    "    return indices[:,:T]\n",
    "\n",
    "def classify_ori(x, mx, L, S, supermask, q,la=0.01):\n",
    "    nj = x.shape[0]\n",
    "\n",
    "    nc = mx.shape[0]\n",
    "    out = 100000 * torch.ones(nj, nc, device=device)\n",
    "    for i in range(nc):\n",
    "        r = response(x[torch.gt(supermask[:, i], 0)], mx[i, :].to(device), L[i, :q, :].to(device), S[i, :q].to(device), la)\n",
    "        out[torch.gt(supermask[:, i], 0), i] = r\n",
    "\n",
    "    py = torch.argmin(out, dim=1)\n",
    "    return py\n",
    "\n",
    "def test_HPPCA(model,mu,L,S,test_loader,T=4,q=100,r=100):\n",
    "    nc=model['nc']\n",
    "    nsc=model['nsc']\n",
    "    ind=model['ind']\n",
    "    indexDict=model['indexDict']\n",
    "    total = 0\n",
    "    wrong = 0\n",
    "    total_wrong = 0\n",
    "    super_correct=0\n",
    "    start = time.time()\n",
    "    density = 0\n",
    "    for data in test_loader:\n",
    "        features, labels = data\n",
    "        labels = torch.squeeze(labels)\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        py = classifyT(features, model['smu'], model['sL'], model['sS'],r, la=0.01, T=T)\n",
    "        superlabels=ind[labels]\n",
    "        #print(model['smu'].shape,py.shape)\n",
    "        super_correct += torch.sum(torch.max((py-superlabels.view(-1,1)==0).float(),dim=1)[0])\n",
    "        supermask = torch.zeros((len(py), nc), device=device)\n",
    "        i = 0\n",
    "        for i in range(len(py)):\n",
    "            for j in range(T):\n",
    "                superlabel = py[i][j]\n",
    "                superIndex = indexDict[int(superlabel)]\n",
    "\n",
    "                supermask[i][superIndex] = 1\n",
    "\n",
    "        density += supermask.sum()\n",
    "        label = classify_ori(features, mu, L, S, supermask,q, la=0.01)\n",
    "\n",
    "        total_wrong += torch.sum(label != labels)\n",
    "        # wrong_list1.append(wrong/len(py))\n",
    "\n",
    "        total += len(py)\n",
    "        end = time.time()\n",
    "        #print('Computation time is', end - start)\n",
    "    #print('super acc:',100*super_correct/total)\n",
    "    density+=nsc*total\n",
    "    density=density.item() / (total * nc)\n",
    "    speedup=1/density\n",
    "    acc=1-total_wrong.item()/total\n",
    "    super_acc=super_correct.item()/total\n",
    "    print('T:%d,q:%d,r:%d,nsc:%d,density:%.3f,speedup:%.1f,accuracy:%.3f,super_acc:%.3f' %(T,q,r,nsc,density,speedup,acc,super_acc))\n",
    "    \n",
    "    result={'density':density,'speedup':speedup,'acc':acc,'super_acc':super_acc}\n",
    "    return result\n",
    "\n",
    "pnames=torch.load('pnames100.pth')\n",
    "start=1\n",
    "torch.cuda.empty_cache()\n",
    "for i in range(0,5):\n",
    "    if 0: # For ImageNet-100\n",
    "        names=pnames[i+1]\n",
    "        mu,L,S=loadClassPPCAs('d:/datasets/ILSVRC2016/model_640',names,device,q=200)\n",
    "        xt,yt=load_data_all('d:/datasets/ILSVRC2016/features_val_640/',names)\n",
    "        print(i,nc,xt.shape,yt.shape)\n",
    "        data=TensorDataset(xt,yt.long())\n",
    "        test_loader=DataLoader(data,batch_size=10000,shuffle=False)\n",
    "    nc=len(names)\n",
    "    for nsc in [33]:\n",
    "        name='c:/training/ppca/hppca_640_1k_%d_%d.pth'%(nsc,i+1)\n",
    "        #name='raw_640_10k_%d_%d.pth'%(nsc,i+1)\n",
    "        model=torch.load(name)\n",
    "        model['sL']=model['sL'].to(device)\n",
    "        model['sS']=model['sS'].to(device)\n",
    "        model['smu']=model['smu'].to(device)\n",
    "        torch.cuda.empty_cache()\n",
    "        for r in [50]:#[0,10,20,50,100,200]:\n",
    "            q=r\n",
    "            for T in [1,5]:\n",
    "                result=test_HPPCA(model,mu,L,S,test_loader,T=T,q=q,r=r)\n",
    "                if start:\n",
    "                    start=0\n",
    "                    res={'T':[],'q':[],'r':[],'i':[],'nsc':[]}\n",
    "                    for k in result.keys():\n",
    "                        res[k]=[]\n",
    "                res['nsc'].append(model['nsc'])\n",
    "                res['T'].append(T)\n",
    "                res['q'].append(q)\n",
    "                res['r'].append(r)\n",
    "                res['i'].append(i+1)\n",
    "                for k in result.keys():\n",
    "                    res[k].append(result[k])\n",
    "                #print(res)\n",
    "        df=pd.DataFrame(res)\n",
    "        print(df)\n",
    "        name='res_hppca.csv'\n",
    "        df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance matrix\n",
      "torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "# not used\n",
    "def computeDisMatrix(mu,Sigma):\n",
    "    print('Computing distance matrix')\n",
    "    nc=mu.shape[0]\n",
    "    mat=torch.zeros((nc,nc),device=device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nc):\n",
    "            di=B_distance(mu[i,:],Sigma[i,:,:],mu[:i,:],Sigma[:i,:])\n",
    "            mat[i, :i] = di\n",
    "\n",
    "    for i in range(0, nc - 1):\n",
    "        mat[i, i+1:] = mat[i+1:, i]\n",
    "    return mat\n",
    "\n",
    "dist=computeDisMatrix(mu,Sigma)\n",
    "print(dist.shape,torch.max(dist))\n",
    "torch.save(dist,'d:/Datasets/ILSVRC2016/dist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=torch.load('d:/Datasets/ILSVRC2016/Model_640/dist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "10 100 640\n",
      "init\n",
      "4\n",
      "9\n",
      "done in 0.6s\n",
      "loss is tensor(8592.9102, device='cuda:0')\n",
      "max cluster is 38\n",
      "loss is tensor(2431.9058, device='cuda:0')\n",
      "max cluster is 38\n",
      "loss is tensor(2431.9058, device='cuda:0')\n",
      "max cluster is 38\n",
      "loss is tensor(2431.9058, device='cuda:0')\n",
      "max cluster is 38\n",
      "Finished training 2.0731048583984375\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "10 100 640\n",
      "init\n",
      "4\n",
      "9\n",
      "done in 0.5s\n",
      "loss is tensor(7767.0073, device='cuda:0')\n",
      "max cluster is 38\n",
      "loss is tensor(2306.5996, device='cuda:0')\n",
      "max cluster is 38\n",
      "loss is tensor(2306.5996, device='cuda:0')\n",
      "max cluster is 38\n",
      "loss is tensor(2306.5996, device='cuda:0')\n",
      "max cluster is 38\n",
      "Finished training 1.9218406677246094\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "10 100 640\n",
      "init\n",
      "4\n",
      "9\n",
      "done in 0.5s\n",
      "loss is tensor(9132.0146, device='cuda:0')\n",
      "max cluster is 31\n",
      "loss is tensor(2294.1294, device='cuda:0')\n",
      "max cluster is 31\n",
      "loss is tensor(2294.1294, device='cuda:0')\n",
      "max cluster is 31\n",
      "loss is tensor(2294.1294, device='cuda:0')\n",
      "max cluster is 31\n",
      "Finished training 1.9215524196624756\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "10 100 640\n",
      "init\n",
      "4\n",
      "9\n",
      "done in 0.5s\n",
      "loss is tensor(7246.1826, device='cuda:0')\n",
      "max cluster is 31\n",
      "loss is tensor(2197.8628, device='cuda:0')\n",
      "max cluster is 31\n",
      "loss is tensor(2183.4045, device='cuda:0')\n",
      "max cluster is 31\n",
      "loss is tensor(2183.4045, device='cuda:0')\n",
      "max cluster is 31\n",
      "Finished training 1.9372782707214355\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "10 100 640\n",
      "init\n",
      "4\n",
      "9\n",
      "done in 0.5s\n",
      "loss is tensor(7955.8940, device='cuda:0')\n",
      "max cluster is 20\n",
      "loss is tensor(2111.8345, device='cuda:0')\n",
      "max cluster is 20\n",
      "loss is tensor(2111.8345, device='cuda:0')\n",
      "max cluster is 20\n",
      "loss is tensor(2111.8345, device='cuda:0')\n",
      "max cluster is 20\n",
      "Finished training 1.9267444610595703\n"
     ]
    }
   ],
   "source": [
    "# Train HPPCA\n",
    "\n",
    "def KL(mu_q,invSigma_q,mu_p,Sigma_p):\n",
    "    with torch.no_grad():\n",
    "        n=mu_p.shape[0]\n",
    "        d=invSigma_q.shape[1]\n",
    "        mu=mu_p-mu_q\n",
    "        muSimu=(mu.unsqueeze(1)@invSigma_q@mu.unsqueeze(2)).squeeze()\n",
    "        #score2=torch.sum(torch.diagonal(invSigma_q@Sigma_p, dim1=-1),dim=1)\n",
    "        tr=torch.sum(invSigma_q.t()*Sigma_p,dim=[1,2])\n",
    "        logdets=torch.logdet(Sigma_p)+torch.logdet(invSigma_q)\n",
    "    return (muSimu+tr-logdets-d)/2\n",
    "\n",
    "def kMeansInit(disMatrix, nsc):\n",
    "    # k-Means++ initialization\n",
    "    # uses a precomputed distance matrix (slow)\n",
    "    with torch.no_grad():\n",
    "        nc=disMatrix.shape[0]\n",
    "        disM = torch.where(disMatrix > 0, disMatrix, torch.zeros(disMatrix.shape, device=device))\n",
    "        init_list = torch.zeros(nsc, device=device).long()\n",
    "\n",
    "        init_list[0] = randint(0, nc - 1)\n",
    "        row = disM[init_list[0],:]\n",
    "        for i in range(1, nsc):\n",
    "            ind = np.random.choice(nc, p=(row / sum(row)).cpu().numpy())\n",
    "            init_list[i] = ind\n",
    "            row, _ = torch.min(torch.stack((row, disM[ind,:]), dim=0), dim=0)\n",
    "    return torch.sort(init_list)[0]\n",
    "\n",
    "def B_distance(mx1,Sigma1,mx2,Sigma2):\n",
    "    # Bhattacharyya distances\n",
    "    mu=mx1-mx2\n",
    "    Sigma=torch.linalg.inv((Sigma2+Sigma1)/2)\n",
    "    #print(Sigma.shape,mu.shape)\n",
    "    Simu=Sigma@mu.unsqueeze(2)\n",
    "    #print(Simu.shape)\n",
    "    dis= mu.unsqueeze(1)@Simu\n",
    "    return dis.squeeze()/8\n",
    "\n",
    "\n",
    "def B_distances(mx1,Sigma1,loader):\n",
    "    # Bhattacharyya distances using a loader\n",
    "    dis=[]\n",
    "    mx1=mx1.to(device)\n",
    "    Sigma1=Sigma1.to(device)\n",
    "    for mui,sigmai in loader:\n",
    "        mui,sigmai=mui.to(device),sigmai.to(device)\n",
    "        mu=mx1-mui\n",
    "        Sigma=sigmai+Sigma1\n",
    "        Sigma=torch.linalg.inv(Sigma/2)\n",
    "        Simu=Sigma@mu.unsqueeze(2)\n",
    "        #print(Simu.shape)\n",
    "        disi= mu.unsqueeze(1)@Simu\n",
    "        dis.append(disi.squeeze())\n",
    "    dis=torch.cat(dis)\n",
    "    dis[dis<0]=0\n",
    "    return dis/8\n",
    "\n",
    "def kMeansInit1(loader, nsc):\n",
    "    # k-Means++ initialization\n",
    "    # computes only what distances it needs\n",
    "    print('init')\n",
    "    t0=time.time()\n",
    "    nc=mu.shape[0]\n",
    "    init_list = torch.zeros(nsc, device=device).long()\n",
    "    ind=randint(0, nc - 1)\n",
    "    init_list[0] = ind\n",
    "    row = B_distances(mu[ind,:],Sigma[ind,:,:],loader)\n",
    "    for i in range(1, nsc):\n",
    "        ind = np.random.choice(nc, p=(row / sum(row)).cpu().numpy())\n",
    "        init_list[i] = ind\n",
    "        di=B_distances(mu[ind,:],Sigma[ind,:,:],loader)\n",
    "        row, _ = torch.min(torch.stack((row, di), dim=0), dim=0)\n",
    "        if i%5==4:\n",
    "            print(i)\n",
    "    print('done in %.1fs'%(time.time()-t0))\n",
    "    return torch.sort(init_list)[0]\n",
    "\n",
    "def generateSuper(mu,sigma):\n",
    "    # the superclass mean and sigma from Theorem 2\n",
    "    mu,sigma=mu.to(device),sigma.to(device)\n",
    "    superMu=torch.mean(mu,dim=0)\n",
    "    s_mu=mu-superMu\n",
    "    n=mu.shape[0]\n",
    "    d=mu.shape[1]\n",
    "    xx=s_mu.unsqueeze(2)@s_mu.unsqueeze(1)\n",
    "    superSigma=torch.mean(xx,dim=0)+torch.mean(sigma,dim=0)\n",
    "    return superMu,superSigma\n",
    "\n",
    "def computeKL(disMatrix,mu,invSigma, mu_p, Sigma_p):\n",
    "    torch.cuda.empty_cache()\n",
    "    nc=mu_p.shape[0]\n",
    "    nsc=mu.shape[0]\n",
    "    with torch.no_grad():\n",
    "        for i in range(nsc):\n",
    "             #   for j in range(int(self.nc/500)):        \n",
    "            disMatrix[:, i] = KL(mu[i],invSigma[i],mu_p,Sigma_p)\n",
    "        score, ind = torch.min(disMatrix, dim=1)\n",
    "        ind = ind\n",
    "        loss = torch.sum(score)\n",
    "        print('loss is', loss)\n",
    "    return ind\n",
    "\n",
    "def max_cluster(ind):\n",
    "    nsc=torch.max(ind)+1\n",
    "    ne=torch.zeros(nsc).long()\n",
    "    for i in range(nsc):\n",
    "        ne[i]=torch.sum(ind==i)\n",
    "    return torch.max(ne).item()\n",
    "\n",
    "def updateParameters(ind, smu, sSigma, mu_p, Sigma_p):\n",
    "    nsc=smu.shape[0]\n",
    "    for i in range(nsc):\n",
    "        mui,si=generateSuper(mu_p[ind == i,:],Sigma_p[ind == i,:,:])\n",
    "        smu[i,:] = mui\n",
    "        sSigma[i,:,:]=si\n",
    "    return smu, sSigma\n",
    "\n",
    "def updateLS(Sigma,q=20, la=0.01):\n",
    "    u, s, v = torch.linalg.svd(Sigma, full_matrices=True)\n",
    "    L=v[:,:q, :]\n",
    "#                self.L[i,:,:] = Li\n",
    "    S = s[:,:q]\n",
    "#    Sigma = (L.permute(0,2,1)*S.unsqueeze(1))@L+la*torch.eye(Sigma.shape[1],device=v.device).unsqueeze(0)\n",
    "#    invSigma = torch.linalg.inv(Sigma)\n",
    "    return L,S#,Sigma,invSigma\n",
    "    \n",
    "def getIndex(ind,nsc,nc):\n",
    "    indexDict={}\n",
    "    for i in range(nsc):\n",
    "        indexDict[i] = []\n",
    "    for i in range(nc):\n",
    "        indexDict[int(ind[i])].append(i)\n",
    "    return indexDict\n",
    "\n",
    "\n",
    "# cluster the class Gaussians\n",
    "pnames=torch.load('pnames100.pth')\n",
    "n_iter=4\n",
    "for it in range(5):\n",
    "    if 1: # For ImageNet-100\n",
    "        names=pnames[it+1]\n",
    "        nc=len(names)\n",
    "        mu,L,S,Sigma=loadClassPPCAs('d:/datasets/ILSVRC2016/model_640',names,device,q=50,loadSigma=1)\n",
    "    data=TensorDataset(mu,Sigma)\n",
    "    loader=DataLoader(data,batch_size=200,shuffle=False)\n",
    "    d=Sigma.shape[1]\n",
    "    for nsc in [10]:\n",
    "        print(nsc,nc,d)\n",
    "        t0=time.time()\n",
    "        #init_list=selectInit(dist,nsc)\n",
    "        init_list=kMeansInit1(loader,nsc)\n",
    "        smu=mu[init_list,:].clone()\n",
    "        sSigma=Sigma[init_list,:,:].clone()\n",
    "        sinvSigma = torch.linalg.inv(sSigma)\n",
    "        disMatrix = torch.zeros((nc, nsc), device=device, dtype=torch.float)\n",
    "        for i in range(n_iter):\n",
    "            ind=computeKL(disMatrix,smu,sinvSigma,mu,Sigma)\n",
    "            print('max cluster is', max_cluster(ind))\n",
    "            smu,sSigma=updateParameters(ind,smu,sSigma,mu,Sigma)\n",
    "            sinvSigma = torch.linalg.inv(sSigma)\n",
    "        sL,sS=updateLS(sSigma,200)\n",
    "        indexDict=getIndex(ind,nsc,nc)\n",
    "        model={'nc':nc,'nsc':nsc,'smu':smu,'sL':sL,'sS':sS,'ind':ind,'indexDict':indexDict}\n",
    "        name='hppca_640_100_%d_%d.pth'%(nsc,it+1)\n",
    "        torch.save(model,name)\n",
    "        print('Finished training', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8836e-07)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def KLs(mu_q,invSigma_q,loader):\n",
    "    mu_q=mu_q.to(device)\n",
    "    invSigma_q=invSigma_q.to(device)\n",
    "    kls=[]\n",
    "    d=invSigma_q.shape[1]\n",
    "    ld=torch.logdet(invSigma_q)\n",
    "    for mui,sigmai in loader:\n",
    "        mui,sigmai=mui.to(device),sigmai.to(device)\n",
    "        mu=mui-mu_q\n",
    "        muSimui=(mu.unsqueeze(1)@invSigma_q@mu.unsqueeze(2)).squeeze()\n",
    "        #score2=torch.sum(torch.diagonal(invSigma_q@Sigma_p, dim1=-1),dim=1)\n",
    "        tri=torch.sum(invSigma_q.t()*sigmai,dim=[1,2])\n",
    "        logdeti=torch.logdet(sigmai)+ld\n",
    "        kls.append(muSimui+tri-logdeti)\n",
    "    kls=torch.cat(kls)\n",
    "    return (kls-d)/2\n",
    "\n",
    "data=TensorDataset(mu,Sigma)\n",
    "loader=DataLoader(data,batch_size=10,shuffle=False)\n",
    "b1 = KLs(mu[0,:],Sigma[0,:,:],loader).cpu()\n",
    "b2 = KL(mu[0,:],Sigma[0,:,:],mu,Sigma).cpu()\n",
    "print(torch.max(torch.abs(b1-b2))/torch.max(torch.abs(b2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "torch.Size([2000, 640])\n",
      "100\n",
      "Finished training 0.971869945526123\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "torch.Size([2000, 640])\n",
      "100\n",
      "Finished training 0.6351423263549805\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "torch.Size([2000, 640])\n",
      "100\n",
      "Finished training 0.6461451053619385\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "torch.Size([2000, 640])\n",
      "100\n",
      "Finished training 0.6441442966461182\n",
      "dict_keys(['mx', 'L', 'S', 'Sigma'])\n",
      "torch.Size([200, 640]) torch.Size([200])\n",
      "100\n",
      "done loading classes\n",
      "torch.Size([2000, 640])\n",
      "100\n",
      "Finished training 0.6461443901062012\n"
     ]
    }
   ],
   "source": [
    "# Train HPPCA raw\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "nsc=33\n",
    "def HPPCA_raw(x,y,nsc,mu,Sigma,random_state):\n",
    "    sc = KMeans(n_clusters=nsc, random_state=random_state, n_init=\"auto\").fit(x.cpu().numpy())\n",
    "    c=torch.tensor(contingency_matrix(y.cpu(), sc.labels_))\n",
    "    ind=torch.argmax(c,dim=1).to(device)\n",
    "    d=x.shape[1]\n",
    "    smu=torch.zeros(nsc,d,device=device)\n",
    "    sSigma=torch.zeros(nsc,d,d,device=device)\n",
    "    smu,sSigma=updateParameters(ind, smu, sSigma, mu, Sigma)\n",
    "    sL,sS=updateLS(sSigma,200)\n",
    "    indexDict=getIndex(ind,nsc,nc)\n",
    "    model={'nc':nc,'nsc':nsc,'smu':smu,'sL':sL,'sS':sS,'ind':ind,'indexDict':indexDict}\n",
    "    return model\n",
    "nsc=10\n",
    "pnames=torch.load('pnames100.pth')\n",
    "for it in range(5):\n",
    "    if 1: # For ImageNet-100\n",
    "        names=pnames[it+1]\n",
    "        nc=len(names)\n",
    "        mu,L,S,Sigma=loadClassPPCAs(path+'model_640',names,device,q=50,loadSigma=1)\n",
    "    x,y=load_subsamples(path+'features_640/',names,20)\n",
    "    t0=time.time()\n",
    "    model=HPPCA_raw(x,y,nsc,mu,Sigma,it+1)\n",
    "    name='raw_640_100_%d_%d.pth'%(nsc,it+1)\n",
    "    torch.save(model,name)\n",
    "    print('Finished training', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
